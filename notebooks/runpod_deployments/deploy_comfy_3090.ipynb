{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91fafb0f",
   "metadata": {},
   "source": [
    "# Deploy ComfyUI on a RunPod GPU (3090)\n",
    "This notebook builds and optionally runs `runpodctl` commands to favorite a template and create a comfy instance on a 3090 GPU.\n",
    "\n",
    "**Assumptions:**\n",
    "- `runpodctl` is installed and you are authenticated (run `runpodctl auth login`).\n",
    "- Template identifiers and exact CLI subcommands may vary by `runpodctl` version. The notebook defaults to a dry run (safe).\n",
    "- Update `DRY_RUN = False` to actually execute commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f896596d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 46) (2085578933.py, line 46)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 46\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f'  {i}. {item.get(\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unterminated string literal (detected at line 46)\n"
     ]
    }
   ],
   "source": [
    "# Core imports and small helper runner\n",
    "import subprocess, time, os, json\n",
    "from pathlib import Path\n",
    "DRY_RUN = True  # Set to False to actually run commands\n",
    "def run(cmd):\n",
    "    # prints the command and only executes if DRY_RUN is False\n",
    "    print('\\n$ ' + ' '.join(cmd))\n",
    "    if not DRY_RUN:\n",
    "        subprocess.run(cmd, check=True)\n",
    "\n",
    "# Template history: stores recent template/gpu/deployment choices so the notebook can default to the last set\n",
    "HISTORY_FILE = Path('notebooks/runpod_deployments/.templates_history.json')\n",
    "MAX_HISTORY = 20\n",
    "\n",
    "def load_history():\n",
    "    if not HISTORY_FILE.exists():\n",
    "        return []\n",
    "    try:\n",
    "        return json.loads(HISTORY_FILE.read_text()) or []\n",
    "    except Exception as e:\n",
    "        print('Failed to read history:', e)\n",
    "        return []\n",
    "\n",
    "def save_history(hist):\n",
    "    try:\n",
    "        HISTORY_FILE.parent.mkdir(parents=True, exist_ok=True)\n",
    "        HISTORY_FILE.write_text(json.dumps(hist[:MAX_HISTORY], indent=2))\n",
    "    except Exception as e:\n",
    "        print('Failed to save history:', e)\n",
    "\n",
    "def pick_template_interactive(history):\n",
    "    \"\"\"Return a dict with keys: template, gpu, deployment, extra\"\"\"\n",
    "    default = history[0] if history else None\n",
    "    if default:\n",
    "        print('Default (last used):')\n",
    "        print('  template:', default.get('template'))\n",
    "        print('  gpu:', default.get('gpu'))\n",
    "        print('  deployment:', default.get('deployment'))\n",
    "    else:\n",
    "        print('No template history found; you will be asked to provide values')\n",
    "\n",
    "    # Offer choices from history\n",
    "    if history:\n",
    "        print('\\nRecent templates:')\n",
    "        for i, item in enumerate(history[:10], 1):\n",
    "            print(f'  {i}. {item.get(\n",
    ")} (gpu={item.get(\n",
    ")}, deployment={item.get(\n",
    ")})')\n",
    "        print('  0. Enter a new template')\n",
    "        choice = input('Choose number to reuse, or press Enter to accept default, or 0 to enter new: ').strip()\n",
    "        if choice == '':\n",
    "            return default\n",
    "        if choice.isdigit():\n",
    "            n = int(choice)\n",
    "            if n == 0:\n",
    "                pass  # fall through to manual entry\n",
    "            elif 1 <= n <= len(history):\n",
    "                return history[n-1]\n",
    "    # Manual entry flow\n",
    "    template = input('Enter template name (e.g. comfy/comfyui-template): ').strip()\n",
    "    gpu = input('Enter gpu type (default 3090): ').strip() or '3090'\n",
    "    deployment = input('Enter deployment name (leave blank for autogenerated): ').strip()\n",
    "    if not deployment:\n",
    "        deployment = f'comfy-{gpu}-{int(time.time())}'\n",
    "    extra = input('Extra CLI args (optional): ').strip()\n",
    "    return {'template': template, 'gpu': gpu, 'deployment': deployment, 'extra': extra}\n",
    "\n",
    "# Load history and pick a configuration\n",
    "history = load_history()\n",
    "selected = pick_template_interactive(history)\n",
    "template_name = selected.get('template') if isinstance(selected, dict) else selected\n",
    "gpu_type = selected.get('gpu', '3090') if isinstance(selected, dict) else '3090'\n",
    "deployment_name = selected.get('deployment', f'comfy-{gpu_type}-{int(time.time())}') if isinstance(selected, dict) else f'comfy-{gpu_type}-{int(time.time())}'\n",
    "extra_args = selected.get('extra', '') if isinstance(selected, dict) else ''\n",
    "\n",
    "# Persist selection to top of history\n",
    "new_entry = {'template': template_name, 'gpu': gpu_type, 'deployment': deployment_name, 'extra': extra_args}\n",
    "# remove identical entries\n",
    "history = [e for e in history if e.get('template') != new_entry['template'] or e.get('gpu') != new_entry['gpu'] or e.get('deployment') != new_entry['deployment']]\n",
    "history.insert(0, new_entry)\n",
    "save_history(history)\n",
    "\n",
    "print(f'Using template={template_name} gpu={gpu_type} deployment={deployment_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c388ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770e4734",
   "metadata": {},
   "source": [
    "## Favorite the ComfyUI template\n",
    "Update `template_name` below to match your RunPod template identifier. If your `runpodctl` uses different subcommands, adjust accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c540d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "$ runpodctl templates favorite comfy/comfyui-template\n"
     ]
    }
   ],
   "source": [
    "# Favorite the selected template (idempotent)\n",
    "run(['runpodctl', 'templates', 'favorite', template_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68520461",
   "metadata": {},
   "source": [
    "## Create the deployment\n",
    "Adjust `gpu_type` and `deployment_name` as needed. The `--gpu` flag is used as a placeholder — adapt to your `runpodctl` version if it differs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43f07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_name = 'comfy-3090-test'\n",
    "gpu_type = '3090'\n",
    "cmd = ['runpodctl', 'deployments', 'create', '--name', deployment_name, '--template', template_name, '--gpu', gpu_type]\n",
    "run(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9756314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: poll status (runs only when DRY_RUN is False)\n",
    "if not DRY_RUN:\n",
    "    for _ in range(30):\n",
    "        subprocess.run(['runpodctl','deployments','status','--name',deployment_name])\n",
    "        time.sleep(5)\n",
    "else:\n",
    "    print('Dry run complete — set DRY_RUN = False to execute')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
