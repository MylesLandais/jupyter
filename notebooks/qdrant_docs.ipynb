{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4b6e0ad-6d42-4518-80ed-41ea279e33a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-23 03:24:34] INFO configuration_clip.py:258: `text_config` is `None`. Initializing the `JinaCLIPTextConfig` with default values.\n",
      "[2025-11-23 03:24:34] INFO configuration_clip.py:265: `vision_config` is `None`. initializing the `JinaCLIPVisionConfig` with default values.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Jina CLIP v2 model (768-dim text embeddings)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/jina-clip-implementation:\n",
      "- transform.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f865a66a574fb2be9ea87f80571b49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.73G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/huggingface/modules/transformers_modules/jinaai/jina_hyphen_clip_hyphen_implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/modeling_clip.py:140: UserWarning: Flash attention is not installed. Check https://github.com/Dao-AILab/flash-attention?tab=readme-ov-file#installation-and-features for installation instructions, disabling\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a07a19525754ee8b8ca8f338c5290cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d51bac22cee41a4bf6771bcff3db09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_xlm_roberta.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- configuration_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deaf94c3ec364582a85984e9117dddfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_lora.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f772dc42304c22955ca9be34d2aad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_xlm_roberta.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22af9d29e76b47639ac6c9f45a5f9920",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mha.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74ce54369c474044aff694bcc3638250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "rotary.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mha.py\n",
      "- rotary.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a510b09bb16d44a399cc7d1be4e69a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mlp.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- mlp.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f83335134e412da1186af56a7ff5b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "block.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab67fc464a844cf492e7686c40794d26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "stochastic_depth.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- block.py\n",
      "- stochastic_depth.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c423aa55ef642bab2f6516e5ccc1cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "xlm_padding.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- xlm_padding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6cdacdce8d4dbfa0c5230a4a9f061e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "embedding.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_xlm_roberta.py\n",
      "- mha.py\n",
      "- mlp.py\n",
      "- block.py\n",
      "- xlm_padding.py\n",
      "- embedding.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "A new version of the following files was downloaded from https://huggingface.co/jinaai/xlm-roberta-flash-implementation:\n",
      "- modeling_lora.py\n",
      "- modeling_xlm_roberta.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c72225c2614bb2a5c10b735d615fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adb3fd2d8ac408cb6e2eb33c33a7294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c106d59763474ad6b17bf76d242deca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa0d36ec53b4152b4e96e270905c9a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab249c9455e9475197298ae521fcc1b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d94530915da145e98b417415e4e790dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on GPU\n",
      "Processing documents...\n",
      "Extracting from: /home/jovyan/workspace/Datasets/shadow-lb/2014 Martin Fowler - Refactoring_Recl.epub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Could not load translations for en-US\n",
      "  data file translations/en.yaml not found\n",
      "[2025-11-23 03:25:18] WARNING __init__.py:535: Could not load translations for en-US\n",
      "  data file translations/en.yaml not found\n",
      "[WARNING] The term Abstract has no translation defined.\n",
      "\n",
      "[2025-11-23 03:25:18] WARNING __init__.py:535: The term Abstract has no translation defined.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from: /home/jovyan/workspace/Datasets/shadow-lb/Refactoring Improving the Design of Existing Code, 2nd Edition by Martin Fowler.epub\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] Could not load translations for en-US\n",
      "  data file translations/en.yaml not found\n",
      "[2025-11-23 03:25:24] WARNING __init__.py:535: Could not load translations for en-US\n",
      "  data file translations/en.yaml not found\n",
      "[WARNING] The term Abstract has no translation defined.\n",
      "\n",
      "[2025-11-23 03:25:24] WARNING __init__.py:535: The term Abstract has no translation defined.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edition 1: 357 chunks\n",
      "Edition 2: 385 chunks\n",
      "\n",
      "Creating vector index...\n",
      "Generating embeddings for 357 chunks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29095/351854204.py:94: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  qdrant_client.recreate_collection(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 260\u001b[0m\n\u001b[1;32m    257\u001b[0m path1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/workspace/Datasets/shadow-lb/2014 Martin Fowler - Refactoring_Recl.epub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    258\u001b[0m path2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m~/workspace/Datasets/shadow-lb/Refactoring Improving the Design of Existing Code, 2nd Edition by Martin Fowler.epub\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 260\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath2\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 237\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(edition1_path, edition2_path)\u001b[0m\n\u001b[1;32m    234\u001b[0m collection_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbook_comparison\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    235\u001b[0m create_collection(collection_name)\n\u001b[0;32m--> 237\u001b[0m \u001b[43mindex_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medition1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m index_chunks(chunks2, collection_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medition2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m80\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 112\u001b[0m, in \u001b[0;36mindex_chunks\u001b[0;34m(chunks, collection_name, edition_label, batch_size)\u001b[0m\n\u001b[1;32m    110\u001b[0m batch \u001b[38;5;241m=\u001b[39m chunks[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m    111\u001b[0m texts \u001b[38;5;241m=\u001b[39m [chunk[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[0;32m--> 112\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membed_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m points \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    115\u001b[0m     PointStruct(\n\u001b[1;32m    116\u001b[0m         \u001b[38;5;28mid\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(uuid\u001b[38;5;241m.\u001b[39muuid4()),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch, embeddings)\n\u001b[1;32m    121\u001b[0m ]\n\u001b[1;32m    122\u001b[0m all_points\u001b[38;5;241m.\u001b[39mextend(points)\n",
      "Cell \u001b[0;32mIn[13], line 55\u001b[0m, in \u001b[0;36membed_text\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     52\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 55\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncate_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVECTOR_DIM\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mlast_hidden_state\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     57\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m embeddings \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(embeddings, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina_hyphen_clip_hyphen_implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/modeling_clip.py:649\u001b[0m, in \u001b[0;36mJinaCLIPModel.forward\u001b[0;34m(self, input_ids, pixel_values, return_dict, return_loss, *_, **__)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    639\u001b[0m     input_ids: Union[\u001b[38;5;28;01mNone\u001b[39;00m, torch\u001b[38;5;241m.\u001b[39mTensor, BatchEncoding] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__,\n\u001b[1;32m    645\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[Tuple[Optional[torch\u001b[38;5;241m.\u001b[39mFloatTensor], \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m], CLIPOutput]:\n\u001b[1;32m    646\u001b[0m     return_dict \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    647\u001b[0m         return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m    648\u001b[0m     )\n\u001b[0;32m--> 649\u001b[0m     image_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpixel_values\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m     text_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_text_features(input_ids\u001b[38;5;241m=\u001b[39minput_ids)\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;66;03m# normalized features\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina_hyphen_clip_hyphen_implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/modeling_clip.py:365\u001b[0m, in \u001b[0;36mJinaCLIPModel.get_image_features\u001b[0;34m(self, pixel_values, *_, **__)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_image_features\u001b[39m(\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    356\u001b[0m     pixel_values: Union[\u001b[38;5;28;01mNone\u001b[39;00m, torch\u001b[38;5;241m.\u001b[39mFloatTensor, BatchFeature] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;241m*\u001b[39m_,\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__,\n\u001b[1;32m    359\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    360\u001b[0m     x \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    361\u001b[0m         pixel_values\u001b[38;5;241m.\u001b[39mpixel_values\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pixel_values, BatchFeature)\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m pixel_values\n\u001b[1;32m    364\u001b[0m     )\n\u001b[0;32m--> 365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual_projection(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvision_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina_hyphen_clip_hyphen_implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/eva_model.py:769\u001b[0m, in \u001b[0;36mEVAVisionTransformer.forward\u001b[0;34m(self, x, return_all_features)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_all_features:\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_features(x, return_all_features)\n\u001b[0;32m--> 769\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(x)\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina_hyphen_clip_hyphen_implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/eva_model.py:726\u001b[0m, in \u001b[0;36mEVAVisionTransformer.forward_features\u001b[0;34m(self, x, return_all_features)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, return_all_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 726\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    727\u001b[0m     batch_size, seq_len, _ \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize()\n\u001b[1;32m    729\u001b[0m     cls_tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcls_token\u001b[38;5;241m.\u001b[39mexpand(\n\u001b[1;32m    730\u001b[0m         batch_size, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    731\u001b[0m     )  \u001b[38;5;66;03m# stole cls_tokens impl from Phil Wang, thanks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1775\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1784\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1785\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1788\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1789\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/.cache/huggingface/modules/transformers_modules/jinaai/jina_hyphen_clip_hyphen_implementation/39e6a55ae971b59bea6e44675d237c99762e7ee2/eva_model.py:469\u001b[0m, in \u001b[0;36mPatchEmbed.forward\u001b[0;34m(self, x, **_)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_):\n\u001b[1;32m    468\u001b[0m     target_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m--> 469\u001b[0m     _, __, h, w \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# FIXME look at relaxing size constraints\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m h \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m w \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size[\u001b[38;5;241m1\u001b[39m], (\n\u001b[1;32m    472\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput image size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mh\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mw\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    473\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m*\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_size[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m).\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    474\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "\"\"\"EPUB Edition Comparison RAG System - Local Transformers Edition\n",
    "\n",
    "Compare two editions of a book using hybrid RAG similarity search.\n",
    "\n",
    "Dependencies:\n",
    "    pip install \"unstructured[epub]\" qdrant-client transformers torch numpy\n",
    "    \n",
    "System requirements:\n",
    "    apt install pandoc\n",
    "    GPU: RTX 3070 (8GB VRAM) or better\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import uuid\n",
    "from typing import List, Dict\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "from unstructured.partition.auto import partition\n",
    "from unstructured.chunking.basic import chunk_elements\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Distance, VectorParams, PointStruct\n",
    "\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "print(\"Loading Jina CLIP v2 model (768-dim text embeddings)...\")\n",
    "model = AutoModel.from_pretrained(\"jinaai/jina-clip-v2\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"jinaai/jina-clip-v2\", trust_remote_code=True)\n",
    "model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    print(\"Model loaded on GPU\")\n",
    "else:\n",
    "    print(\"Model loaded on CPU\")\n",
    "\n",
    "VECTOR_DIM = 768\n",
    "\n",
    "\n",
    "def embed_text(texts: List[str]) -> List[List[float]]:\n",
    "    \"\"\"Generate embeddings using Jina CLIP v2 locally via Transformers.\"\"\"\n",
    "    inputs = tokenizer(\n",
    "        texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=8192\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, truncate_dim=VECTOR_DIM)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "        embeddings = embeddings / np.linalg.norm(embeddings, axis=1, keepdims=True)\n",
    "    \n",
    "    return embeddings.tolist()\n",
    "\n",
    "\n",
    "def extract_and_chunk(file_path: str, chunk_size: int = 500, overlap: int = 50) -> List[Dict]:\n",
    "    \"\"\"Extract and chunk document using Unstructured.\"\"\"\n",
    "    print(f\"Extracting from: {file_path}\")\n",
    "    try:\n",
    "        elements = partition(filename=file_path, strategy=\"auto\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing (requires pandoc): {e}\")\n",
    "        return []\n",
    "    \n",
    "    chunks = chunk_elements(\n",
    "        elements,\n",
    "        max_characters=chunk_size * 5,\n",
    "        new_after_n_chars=chunk_size * 4,\n",
    "        overlap=overlap * 5,\n",
    "        overlap_all=True\n",
    "    )\n",
    "    \n",
    "    processed_chunks = []\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        metadata = chunk.metadata.to_dict() if hasattr(chunk.metadata, 'to_dict') else {}\n",
    "        processed_chunks.append({\n",
    "            'text': str(chunk),\n",
    "            'chunk_idx': idx,\n",
    "            'page_number': metadata.get('page_number'),\n",
    "            'filename': metadata.get('filename', file_path),\n",
    "            'id': f\"chunk{idx}\"\n",
    "        })\n",
    "    return processed_chunks\n",
    "\n",
    "\n",
    "def create_collection(collection_name: str, vector_size: int = VECTOR_DIM):\n",
    "    \"\"\"Create Qdrant collection for storing embeddings.\"\"\"\n",
    "    qdrant_client.recreate_collection(\n",
    "        collection_name=collection_name,\n",
    "        vectors_config=VectorParams(size=vector_size, distance=Distance.COSINE)\n",
    "    )\n",
    "\n",
    "\n",
    "def index_chunks(chunks: List[Dict], collection_name: str, edition_label: str, batch_size: int = 50):\n",
    "    \"\"\"Generate embeddings and index chunks in Qdrant.\"\"\"\n",
    "    if not chunks:\n",
    "        print(f\"No chunks to index for {edition_label}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Generating embeddings for {len(chunks)} chunks...\")\n",
    "    all_points = []\n",
    "    \n",
    "    for i in range(0, len(chunks), batch_size):\n",
    "        batch = chunks[i:i + batch_size]\n",
    "        texts = [chunk['text'] for chunk in batch]\n",
    "        embeddings = embed_text(texts)\n",
    "        \n",
    "        points = [\n",
    "            PointStruct(\n",
    "                id=str(uuid.uuid4()),\n",
    "                vector=emb,\n",
    "                payload={**chunk, 'edition': edition_label}\n",
    "            )\n",
    "            for chunk, emb in zip(batch, embeddings)\n",
    "        ]\n",
    "        all_points.extend(points)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    upload_batch_size = 100\n",
    "    for i in range(0, len(all_points), upload_batch_size):\n",
    "        qdrant_client.upsert(\n",
    "            collection_name=collection_name,\n",
    "            points=all_points[i:i + upload_batch_size]\n",
    "        )\n",
    "    \n",
    "    print(f\"Indexed {len(all_points)} chunks for {edition_label}\")\n",
    "\n",
    "\n",
    "def search_similar_chunks(query: str, collection_name: str, top_k: int = 5):\n",
    "    \"\"\"Search for chunks similar to query.\"\"\"\n",
    "    query_embedding = embed_text([query])[0]\n",
    "    return qdrant_client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        limit=top_k\n",
    "    )\n",
    "\n",
    "\n",
    "def compare_editions(query: str, collection_name: str, top_k: int = 3) -> Dict:\n",
    "    \"\"\"Compare how a topic appears in both editions.\"\"\"\n",
    "    all_results = search_similar_chunks(query, collection_name, top_k * 2)\n",
    "    \n",
    "    ed1_results = [r for r in all_results if r.payload['edition'] == 'edition1'][:top_k]\n",
    "    ed2_results = [r for r in all_results if r.payload['edition'] == 'edition2'][:top_k]\n",
    "    \n",
    "    differences = []\n",
    "    for ed1_result in ed1_results:\n",
    "        ed1_embedding = np.array(embed_text([ed1_result.payload['text']])[0])\n",
    "        \n",
    "        best_match = None\n",
    "        best_similarity = -1\n",
    "        \n",
    "        for ed2_result in ed2_results:\n",
    "            ed2_embedding = np.array(embed_text([ed2_result.payload['text']])[0])\n",
    "            similarity = np.dot(ed1_embedding, ed2_embedding) / (\n",
    "                np.linalg.norm(ed1_embedding) * np.linalg.norm(ed2_embedding)\n",
    "            )\n",
    "            \n",
    "            if similarity > best_similarity:\n",
    "                best_similarity = similarity\n",
    "                best_match = ed2_result\n",
    "        \n",
    "        differences.append({\n",
    "            'edition1': {\n",
    "                'text': ed1_result.payload['text'],\n",
    "                'page': ed1_result.payload.get('page_number'),\n",
    "                'score': ed1_result.score\n",
    "            },\n",
    "            'edition2': {\n",
    "                'text': best_match.payload['text'] if best_match else None,\n",
    "                'page': best_match.payload.get('page_number') if best_match else None,\n",
    "                'score': best_match.score if best_match else 0\n",
    "            },\n",
    "            'cross_similarity': float(best_similarity),\n",
    "            'is_different': best_similarity < 0.85\n",
    "        })\n",
    "    \n",
    "    return {\n",
    "        'query': query,\n",
    "        'differences': differences\n",
    "    }\n",
    "\n",
    "\n",
    "def display_comparison(results: Dict):\n",
    "    \"\"\"Print comparison results.\"\"\"\n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"Query: {results['query']}\")\n",
    "    print(f\"{'=' * 80}\\n\")\n",
    "    \n",
    "    for idx, diff in enumerate(results['differences'], 1):\n",
    "        status = 'DIFFERENT' if diff['is_different'] else 'SIMILAR'\n",
    "        print(f\"Match {idx} - {status} ({diff['cross_similarity']:.2%} similarity)\")\n",
    "        print(f\"\\nEdition 1:\")\n",
    "        print(f\"  {diff['edition1']['text'][:200]}...\")\n",
    "        \n",
    "        if diff['edition2']['text']:\n",
    "            print(f\"\\nEdition 2:\")\n",
    "            print(f\"  {diff['edition2']['text'][:200]}...\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "\n",
    "\n",
    "def main(edition1_path: str, edition2_path: str):\n",
    "    \"\"\"Main workflow for comparing two editions.\"\"\"\n",
    "    edition1_path = os.path.expanduser(edition1_path)\n",
    "    edition2_path = os.path.expanduser(edition2_path)\n",
    "    \n",
    "    if not os.path.exists(edition1_path) or not os.path.exists(edition2_path):\n",
    "        print(\"Error: Files not found\")\n",
    "        print(f\"  {edition1_path}\")\n",
    "        print(f\"  {edition2_path}\")\n",
    "        return\n",
    "    \n",
    "    print(\"Processing documents...\")\n",
    "    chunks1 = extract_and_chunk(edition1_path)\n",
    "    chunks2 = extract_and_chunk(edition2_path)\n",
    "    \n",
    "    if not chunks1 or not chunks2:\n",
    "        print(\"Error: Failed to extract chunks\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Edition 1: {len(chunks1)} chunks\")\n",
    "    print(f\"Edition 2: {len(chunks2)} chunks\")\n",
    "    \n",
    "    print(\"\\nCreating vector index...\")\n",
    "    collection_name = \"book_comparison\"\n",
    "    create_collection(collection_name)\n",
    "    \n",
    "    index_chunks(chunks1, collection_name, \"edition1\")\n",
    "    index_chunks(chunks2, collection_name, \"edition2\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Ready for queries. Type 'quit' to exit.\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    while True:\n",
    "        query = input(\"\\nQuery: \").strip()\n",
    "        if query.lower() in ['quit', 'exit', 'q']:\n",
    "            break\n",
    "        if query:\n",
    "            try:\n",
    "                results = compare_editions(query, collection_name)\n",
    "                display_comparison(results)\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {e}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path1 = \"~/workspace/Datasets/shadow-lb/2014 Martin Fowler - Refactoring_Recl.epub\"\n",
    "    path2 = \"~/workspace/Datasets/shadow-lb/Refactoring Improving the Design of Existing Code, 2nd Edition by Martin Fowler.epub\"\n",
    "    \n",
    "    main(path1, path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfff66da-6714-42ad-ba0e-bc875a3dcac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f661a8-52d0-444b-8e9a-4b422f89e043",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
